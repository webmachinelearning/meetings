# WebML WG Teleconference ‚Äì 16 May 2024 - 14:00-15:00 UTC

<details><summary>See the timezone table ...</summary>
<table>
<tr><td> San Francisco <td> Thu, 16 May 2024 <td> 07:00 <td> UTC-7 hours 
<tr><td> Boston <td> Thu, 16 May 2024 <td> 10:00 <td> UTC-4 hours  
<tr><td> London <td> Thu, 16 May 2024 <td> 15:00 <td> UTC+1 hours  
<tr><td> Berlin <td> Thu, 16 May 2024 <td> 16:00 <td> UTC+2 hours 
<tr><td> Helsinki <td> Thu, 16 May 2024 <td> 17:00 <td> UTC+3 hours 
<tr><td> Shanghai <td> Thu, 16 May 2024 <td> 22:00 <td> UTC+8 hours
<tr><td> Tokyo <td> Thu, 16 May 2024 <td> 23:00 <td> UTC+9 hours
<tr><td> UTC <td> Thu, 16 May 2024 <td colspan=2> 14:00 UTC
</table>

Other locations: https://www.timeanddate.com/worldclock/fixedtime.html?iso=20240516T14
</details>

## Logistics

* Chair: Anssi
* Scribe: ? (see [howto](https://github.com/webmachinelearning/meetings/blob/main/scribe-howto.md), volunteers welcome!)
* IRC: irc://irc.w3.org:6667/#webmachinelearning
* IRC web client: https://irc.w3.org/?channels=#webmachinelearning
* Joining instructions: https://lists.w3.org/Archives/Member/internal-webmachinelearning/2023Jun/0000.html
* Minutes: https://www.w3.org/2024/05/16-webmachinelearning-minutes.html

## Agenda

### ‚ÑπÔ∏è NPU support 

We agreed to start formalize the NPU support with the simplest design (option 1: deviceType: "npu") informed by implementation experience. Review a draft PR if available, discuss any new information and considerations brought to the group's attention in the issue. Discuss privacy and fingerprinting considerations of the expanded three bits of entropy.

- ‚®Ä WebNN should support NPU and QDQ operations https://github.com/webmachinelearning/webnn/issues/623

Related:

- ‚õ≠ Chromium implementation (NPU device type) https://chromium-review.googlesource.com/c/chromium/src/+/5330647

### ‚ÑπÔ∏è Open issues and PRs

Discuss open issues and review PRs based on your feedback:

- ‚®Ä All [open issues](https://github.com/webmachinelearning/webnn/issues)
- ‚õô All [open pull requests](https://github.com/webmachinelearning/webnn/pulls)

A curated shortlist of recently discussed issues below. If any are addressed prior to the meeting, we'll debrief the group on the changes to keep everyone up to date with significant developments. Please refer to the [triage guidance](https://github.com/webmachinelearning/webnn/blob/main/docs/IssueTriage.md) for more on our triage practices.

#### üè∑Ô∏è Debrief on PRs merged recently

The editors and PR authors will debrief the group on substantive PRs that got merged in the last few weeks, answer question from the group.

- ‚õô Recently [merged PRs](https://github.com/webmachinelearning/webnn/pulls?q=is%3Apr+is%3Amerged)

#### üè∑Ô∏è [process](https://github.com/webmachinelearning/webnn/labels/process) 

- üÜï Introduce "interop" label
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/673
  - ‚õô https://github.com/webmachinelearning/webnn/pull/682
  - ‚ò∞ Introduce the new "interop" triage label

- üÜï TypeScript Types Declarations for WebNN
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/677
  - ‚ò∞ Review a proposal for a possible new WebML CG deliverable (note: *Community* Group)

- Broad device coverage and maintainability
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/453
  - ‚ò∞ Revisit this high-level issue to discuss what has been done, what remains to be done, disseminate any new information
 
#### üè∑Ô∏è [bug](https://github.com/webmachinelearning/webnn/labels/bug)

- ArgMax/Min selectLastIndex is not supported on CoreML
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/652
  - ‚ò∞ Proposal to remove selectLastIndex parameter

- Consider changing output type of ArgMax/Argmin to int32, or allow passing output_type
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/653
  - ‚ò∞ Discussion to unblock exploration into option 2) allow passing output data type as a parameter

#### üè∑Ô∏è [question](https://github.com/webmachinelearning/webnn/labels/question)

- üÜï Make MLOperandDescriptor.dimensions a FrozenArray
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/670
  - ‚ò∞ Discussion on frozen array type subtleties

- üÜï Reconsider MLOperand methods
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/666
  - ‚ò∞ Review 4 options proposed for the MLOperand methods

- Do we need an MLConstantOperand?
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/668
  - ‚ò∞ Revisit with new information from XNNPACK 

#### üè∑Ô∏è [feature request](https://github.com/webmachinelearning/webnn/labels/feature%20request)

- üÜï Type casting all the things
  - ‚®Ä Scalar values https://github.com/webmachinelearning/webnn/issues/678
  - ‚®Ä fp/int <-> uint https://github.com/webmachinelearning/webnn/issues/489
  - ‚®Ä fp64 -> fp32/fp16 https://github.com/webmachinelearning/webnn/issues/325
  - ‚ò∞ Discussion to clarify casting behavior, an early proposal in #678

- Allow checking whether operators/types are supported for a backend before creating a graph
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/463
  - ‚ò∞ Discuss new information from related uint64/int64 data type #654 and MLConstantOperand #668 issues

- MLNumber
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/442
  - ‚õô https://github.com/webmachinelearning/webnn/pull/647
  - ‚ò∞ Review (draft) PR as appropriate

- Rename MLOperandDescriptor's dimensions to shape
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/669
  - ‚õô  https://github.com/webmachinelearning/webnn/pull/676 
  - ‚ò∞ Review (draft) PR as appropriate

- Consider adding node labels for more diagnosable error messages for async errors
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/585
  - ‚ò∞ Review alternatives A) add to options dict B) extend MLOperand's label field C) keep current

#### üè∑Ô∏è [operator specific](https://github.com/webmachinelearning/webnn/labels/operator%20specific)

- argMax/Min only support scalar axis in TFLite runtime
  - ‚®Ä https://github.com/webmachinelearning/webnn/issues/629
  - ‚ò∞ Review other backends and frameworks
